{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 295335,
     "status": "ok",
     "timestamp": 1743631555373,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "FRVAv1SrIlJP",
    "outputId": "305b6d7b-b5f3-4248-d7c2-d078a5b8b89a"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 4143,
     "status": "error",
     "timestamp": 1743631559519,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "CuPVTAcXJAyI",
    "outputId": "fccbed75-5825-4db5-dc38-ba55ecaf8802"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1743631559581,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "fQO7SmPCOzhx"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN\n",
    "from tqdm.notebook import tqdm\n",
    "import base64\n",
    "from IPython.display import HTML, Video\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 299610,
     "status": "aborted",
     "timestamp": 1743631559582,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "7zcEOwE58znv"
   },
   "outputs": [],
   "source": [
    "class FaceBlurPipeline:\n",
    "    def __init__(self, input_path,\n",
    "                 output_path, batch_size=16,\n",
    "                 blur_ksize=(99, 99),\n",
    "                 blur_sigma=30):\n",
    "        \"\"\"\n",
    "        Initializes the face blurring pipeline.\n",
    "\n",
    "        Parameters:\n",
    "            input_path (str): Path to the input video file.\n",
    "            output_path (str): Path where the output video will be saved.\n",
    "            batch_size (int): Number of frames to process in a batch.\n",
    "            blur_ksize (tuple): Kernel size for Gaussian blur.\n",
    "            blur_sigma (int): Standard deviation for Gaussian blur.\n",
    "        \"\"\"\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.batch_size = batch_size\n",
    "        self.blur_ksize = blur_ksize\n",
    "        self.blur_sigma = blur_sigma\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.mtcnn = MTCNN(keep_all=True, device=self.device)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(self.input_path)\n",
    "        if not self.cap.isOpened():\n",
    "            raise IOError(\"Error opening video file: \" + self.input_path)\n",
    "\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.width  = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter(self.output_path, fourcc, self.fps, (self.width, self.height))\n",
    "\n",
    "    def blur_face(self, frame, box):\n",
    "        \"\"\"\n",
    "        Applies a Gaussian blur to the region of the frame defined by the bounding box.\n",
    "\n",
    "        Parameters:\n",
    "            frame (ndarray): The frame image (BGR format).\n",
    "            box (array-like): The bounding box [x1, y1, x2, y2] for the face.\n",
    "\n",
    "        Returns:\n",
    "            The frame with the specified region blurred.\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = [int(b) for b in box]\n",
    "        x1 = max(x1, 0)\n",
    "        y1 = max(y1, 0)\n",
    "        x2 = min(x2, frame.shape[1])\n",
    "        y2 = min(y2, frame.shape[0])\n",
    "\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        face_blurred = cv2.GaussianBlur(face, self.blur_ksize, self.blur_sigma)\n",
    "        frame[y1:y2, x1:x2] = face_blurred\n",
    "        return frame\n",
    "\n",
    "    def process_video(self):\n",
    "        \"\"\"\n",
    "        Processes the video to detect and blur faces using batch processing.\n",
    "        Writes the processed frames to the output video file.\n",
    "        \"\"\"\n",
    "        frames_batch = []\n",
    "        orig_frames_batch = []\n",
    "        pbar = tqdm(total=self.frame_count, desc='Processing Frames')\n",
    "\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frames_batch.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            orig_frames_batch.append(frame)\n",
    "\n",
    "            if len(frames_batch) == self.batch_size:\n",
    "                self._process_batch(frames_batch, orig_frames_batch, pbar)\n",
    "                frames_batch = []\n",
    "                orig_frames_batch = []\n",
    "\n",
    "        if len(frames_batch) > 0:\n",
    "            self._process_batch(frames_batch, orig_frames_batch, pbar)\n",
    "\n",
    "        pbar.close()\n",
    "        self.cap.release()\n",
    "        self.out.release()\n",
    "        print(\"Processing complete. Output saved to:\", self.output_path)\n",
    "\n",
    "    def _process_batch(self, frames_batch, orig_frames_batch, pbar):\n",
    "        \"\"\"\n",
    "        Helper function to process a batch of frames.\n",
    "        \"\"\"\n",
    "        # Convert list of frames (RGB) to PIL images (MTCNN expects PIL images)\n",
    "        pil_batch = [Image.fromarray(frame) for frame in frames_batch]\n",
    "        boxes_batch, _ = self.mtcnn.detect(pil_batch)\n",
    "\n",
    "        # Process each frame in the batch\n",
    "        for idx, boxes in enumerate(boxes_batch):\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    orig_frames_batch[idx] = self.blur_face(orig_frames_batch[idx], box)\n",
    "            self.out.write(orig_frames_batch[idx])\n",
    "            pbar.update(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def display_video(video_path, width=640, height=480):\n",
    "        \"\"\"\n",
    "        Displays a video in the notebook by embedding it in HTML.\n",
    "\n",
    "        Parameters:\n",
    "            video_path (str): Path to the video file.\n",
    "            width (int): Display width.\n",
    "            height (int): Display height.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(video_path, \"rb\") as video_file:\n",
    "                video_bytes = video_file.read()\n",
    "            video_base64 = base64.b64encode(video_bytes).decode('utf-8')\n",
    "            html_code = f\"\"\"\n",
    "            <video width=\"{width}\" height=\"{height}\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\">\n",
    "                Your browser does not support the video tag.\n",
    "            </video>\n",
    "            \"\"\"\n",
    "            return HTML(html_code)\n",
    "        except Exception as e:\n",
    "            return f\"Error displaying video: {e}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def display_video_ipython(video_path, width=640, height=480):\n",
    "        \"\"\"\n",
    "        Displays a video using IPython's Video widget.\n",
    "\n",
    "        Parameters:\n",
    "            video_path (str): Path to the video file.\n",
    "            width (int): Display width.\n",
    "            height (int): Display height.\n",
    "        \"\"\"\n",
    "        return Video(video_path, width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1743631559583,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "yYIJJQa8PJyj"
   },
   "outputs": [],
   "source": [
    "input_video = '/content/drive/MyDrive/datasets/People Walking.mp4' # Change Path Here before execution\n",
    "output_video = 'output_video_blurred.mp4'\n",
    "\n",
    "pipeline = FaceBlurPipeline(input_path=input_video,\n",
    "                            output_path=output_video,\n",
    "                            batch_size=512)\n",
    "\n",
    "print(\"Input Video:\")\n",
    "display_output = FaceBlurPipeline.display_video(input_video)\n",
    "display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1743631559584,
     "user": {
      "displayName": "Indranil Biswas",
      "userId": "07557696266877999315"
     },
     "user_tz": 300
    },
    "id": "P9MCZ16VPdvK"
   },
   "outputs": [],
   "source": [
    "pipeline.process_video()\n",
    "\n",
    "print(\"Output Video (alternative display):\")\n",
    "FaceBlurPipeline.display_video_ipython(output_video)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL0ZYjLdNFsX1Y+V1Rd7Kx",
   "mount_file_id": "1bEvEYwoGnXD9m28Br6E37f-igv32xYH1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
